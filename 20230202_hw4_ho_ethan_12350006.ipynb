{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I install my own implementation of Professor Boonstra's \"memoize DataFrame to disk\" feature. The source code can be found at [github.com/ethho/memoize](https://github.com/ethho/memoize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ethho/memoize.git\n",
      "  Cloning https://github.com/ethho/memoize.git to /tmp/pip-req-build-zqs6fve2\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ethho/memoize.git /tmp/pip-req-build-zqs6fve2\n",
      "  Resolved https://github.com/ethho/memoize.git to commit bef633bd22e4acde44cccb63399a176c6cef79b9\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install git+https://github.com/ethho/memoize.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, probplot\n",
    "import quandl\n",
    "import functools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from src.ubacktester import (\n",
    "    BacktestEngine, StrategyBase, PositionBase, FeedBase,\n",
    "    PlotlyPlotter, FeedID, PriceFeed, px_plot, ClockBase\n",
    ")\n",
    "from memoize.dataframe import memoize_df\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 20230202_hw4_ho_ethan_12350006\n",
    "\n",
    "@mpcs\n",
    "@finm33550\n",
    "\n",
    "Ethan Ho 2/2/2023\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration & Helper Functions\n",
    "\n",
    "The following cell contains helper functions and configuration options that I will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secrets(fp='./secrets.json'):\n",
    "    \"\"\"\n",
    "    Reads secret values such as API keys from a JSON-formatted file at `fp`.\n",
    "    \"\"\"\n",
    "    with open(fp, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def get_quandl_api_key() -> str:\n",
    "    \"\"\"\n",
    "    Returns Quandl API key stored in secrets.json.\n",
    "    \"\"\"\n",
    "    secrets = get_secrets()\n",
    "    key = secrets.get('NASTAQ_DATA_API_KEY')\n",
    "    assert key, f\"NASTAQ_DATA_API_KEY field in secrets.json is empty or does not exist\"\n",
    "    return key\n",
    "\n",
    "def strip_str_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a DataFrame, strips values in columns with string or object\n",
    "    dtype. I noticed that this was an issue when I saw some m_ticker values\n",
    "    like \"AAPL       \" with trailing whitespace.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_object_dtype(df[col]):\n",
    "            df[col] = df[col].str.strip()\n",
    "    return df\n",
    "\n",
    "@memoize_df(cache_dir='/tmp/memoize')\n",
    "def fetch_quandl_quotemedia_prices(\n",
    "    start_date, end_date, ticker\n",
    ") -> pd.DataFrame:\n",
    "    df = quandl.get_table(\n",
    "        'QUOTEMEDIA/PRICES',\n",
    "        date={'gte': start_date, 'lte': end_date},\n",
    "        ticker=ticker,\n",
    "        api_key=get_quandl_api_key(),\n",
    "        paginate=True,\n",
    "    )\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "    return df\n",
    "\n",
    "@memoize_df(cache_dir='/tmp/memoize')\n",
    "def fetch_quandl_tbill_prices(\n",
    "    start_date, end_date,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Fetch table of treasury bill prices from Quandl.\"\"\"\n",
    "    df = quandl.get(\n",
    "        ['USTREASURY/BILLRATES'],\n",
    "        returns=\"pandas\",\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        ticker=ticker,\n",
    "        api_key=get_quandl_api_key(),\n",
    "    )\n",
    "    df = df.reset_index().rename(columns={'Date': 'date'})\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "    return df\n",
    "\n",
    "def unique_index_keys(df, level=0) -> List[str]:\n",
    "    return df.index.get_level_values(level=level).unique().tolist()\n",
    "\n",
    "def risk_free_rate(**kw) -> float:\n",
    "    \"\"\"Calculates risk-free rate R_f from the 3-month T-bill rate.\"\"\"\n",
    "    tbill_prices = fetch_quandl_tbill_prices(**kw)\n",
    "    tbill_returns = tbill_prices['USTREASURY/BILLRATES - 13 Wk Coupon Equiv']\n",
    "    return tbill_returns.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fetch High Frequency Trading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started by unzipping the data using `gzip -d *.delim.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Crypto/2021/For_Homework/book_narrow_BTC-USD_2021.delim\n",
      "data/Crypto/2021/For_Homework/book_narrow_ETH-BTC_2021.delim\n",
      "data/Crypto/2021/For_Homework/book_narrow_ETH-USD_2021.delim\n",
      "data/Crypto/2021/For_Homework/trades_narrow_BTC-USD_2021.delim\n",
      "data/Crypto/2021/For_Homework/trades_narrow_ETH-BTC_2021.delim\n",
      "data/Crypto/2021/For_Homework/trades_narrow_ETH-USD_2021.delim\n"
     ]
    }
   ],
   "source": [
    "!ls data/Crypto/2021/For_Homework/*.delim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Crypto/2022/trades_narrow_BTC-USD_2022.delim\n",
      "data/Crypto/2022/trades_narrow_ETH-BTC_2022.delim\n",
      "data/Crypto/2022/trades_narrow_ETH-USD_2022.delim\n"
     ]
    }
   ],
   "source": [
    "!ls data/Crypto/2022/*.delim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I compiled almost all of the accumulation simulation logic into the below class. Since our simulation is fairly simple, I did use my backtesting engine `ubacktester` to a significant degree, though I did use it's plotting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_to_pow(val: int, pow10: int = 6) -> int:\n",
    "    n = pow10 + 1\n",
    "    hi, lo = str(val)[:-n], str(val)[-n:]\n",
    "    roundup = lambda x: int(ceil(x / 10.0)) * 10\n",
    "    suffix = str(roundup(int(lo[:2])))[0] + (pow10 * '0')\n",
    "    final = int(hi + suffix)\n",
    "    assert len(str(final)) == len(str(val))\n",
    "    return final\n",
    "\n",
    "class InsufficientRowsError(Exception):\n",
    "    pass\n",
    "\n",
    "class AccumulateRunner(dict):\n",
    "\n",
    "    def __init__(\n",
    "        self, side: int = 1,\n",
    "        downsample_rate: int = 6, # 1e6 ns, or 1 ms\n",
    "    ):\n",
    "        assert side in (1, -1)\n",
    "        self.side = side\n",
    "        self.downsample_rate = downsample_rate\n",
    "\n",
    "    # @profiler()\n",
    "    def mark_qualified_trades(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df['dt_ds'] = (\n",
    "            pd.Series(df.index, dtype=np.int64)\n",
    "            .apply(downsample_to_pow, args=[self.downsample_rate])\n",
    "            .values\n",
    "        )\n",
    "        grp = df.groupby('dt_ds', group_keys=False).apply(self._mark_qualified)\n",
    "        grp.index.name = 'dt'\n",
    "        # breakpoint()\n",
    "        return grp\n",
    "\n",
    "    def _mark_qualified(self, df):\n",
    "        if len(df) == 1:\n",
    "            df['is_qual'] = 1\n",
    "            return df\n",
    "        if self.side > 0:\n",
    "            qual_price = df['PriceMillionths'].max()\n",
    "        else:\n",
    "            qual_price = df['PriceMillionths'].min()\n",
    "        qualified_mask = df['PriceMillionths'] == qual_price\n",
    "        df['is_qual'] = qualified_mask.astype(int)\n",
    "        return df\n",
    "\n",
    "    @memoize_df(cache_dir='data/memoize', cache_lifetime_days=None)\n",
    "    def get_trades_data(\n",
    "        self, fp, downsample_rate, side, start_date_ns,\n",
    "        row_limit,\n",
    "    ):\n",
    "        df = pd.read_csv(fp, delim_whitespace=True)\n",
    "        df.rename(columns={\n",
    "            'timestamp_utc_nanoseconds': 'dt',\n",
    "        }, inplace=True)\n",
    "        df.sort_values(by='dt', inplace=True)\n",
    "        df['Side'] = df['Side'].astype(int)\n",
    "        print(\n",
    "            f\"Dates in trades data {fp=} range between \"\n",
    "            f\"{df['dt'].min()} ({pd.to_datetime(df['dt'].min())}) and \"\n",
    "            f\"{df['dt'].max()} ({pd.to_datetime(df['dt'].max())})\"\n",
    "        )\n",
    "        df.drop(columns=['received_utc_nanoseconds'], inplace=True)\n",
    "        # assert not (df['Side'] == 0).any()\n",
    "        df = df[df['Side'] / side > 0]\n",
    "        df.set_index('dt', inplace=True)\n",
    "        df = df.loc[start_date_ns:].iloc[:int(row_limit)]\n",
    "        df = self.mark_qualified_trades(df)\n",
    "        df = df.convert_dtypes()\n",
    "        # breakpoint()\n",
    "        return df\n",
    "\n",
    "    # @profiler()\n",
    "    @memoize_df(cache_dir='data/memoize', cache_lifetime_days=None)\n",
    "    def run_accumulate_strat(\n",
    "        self, fp,\n",
    "        start_date='1970-01-01', # trim data starting at this date\n",
    "        target_prt_rate=0.01, # 1% of traded volume\n",
    "        target_notional=1e6, # stop trading when notional has reached this\n",
    "        fee_rate=50, # basis points on notional\n",
    "        row_limit=1e5, # number of trades to pull from data\n",
    "    ):\n",
    "        start_date_ns = pd.to_datetime(start_date, unit='ns').value\n",
    "        df = self.get_trades_data(\n",
    "            fp=fp, downsample_rate=self.downsample_rate, side=self.side,\n",
    "            start_date_ns=start_date_ns, row_limit=row_limit,\n",
    "        )\n",
    "        df = df.convert_dtypes()\n",
    "        if 'dt' in df.columns:\n",
    "            df.set_index('dt', inplace=True)\n",
    "\n",
    "        # Define masks for same side and qualifying trades\n",
    "        same_side = df['Side'] * self.side > 0\n",
    "        qual_mask = same_side & df['is_qual']\n",
    "\n",
    "        # Calculate cumulative volume over time for each side, for all trades,\n",
    "        # and for qualifying trades.\n",
    "        df.loc[same_side, 'cum_volm_side'] = df.loc[same_side, 'SizeBillionths'].cumsum()\n",
    "        df.loc[~same_side, 'cum_volm_side'] = df.loc[~same_side, 'SizeBillionths'].cumsum()\n",
    "        df['cum_volm_all'] = df.loc[:, 'SizeBillionths'].cumsum()\n",
    "        df['cum_volm_qual'] = pd.NA\n",
    "        df.loc[qual_mask, 'cum_volm_qual'] = df.loc[qual_mask, 'SizeBillionths'].cumsum()\n",
    "        df = df.convert_dtypes()\n",
    "\n",
    "        # Calculate target participation for each qualifying trade (billionths).\n",
    "        # In theory, the below calculation should get us the same as\n",
    "        # df['cum_volm_qual'] * target_prt_rate. They're not exactly equal\n",
    "        # due to the rounding we do with astype(int)\n",
    "        df['target_prt'] = (same_side.astype(int) * df['is_qual'] * target_prt_rate * df['SizeBillionths'])#.astype(int)\n",
    "        df['target_prt_cumsum'] = df['target_prt'].cumsum()\n",
    "        # Approximately equal:\n",
    "        # df['target_prt_cumsum'] = (df['cum_volm_qual'] * target_prt_rate).astype(int)\n",
    "\n",
    "        # Calculate notional (billionths), fees (billionths), and VWAP\n",
    "        df['notional'] = (df['target_prt'] * (df['PriceMillionths'] / 1e6))#.astype(int)\n",
    "        # df['notional_cumsum'] = df['notional'].cumsum().astype(int)\n",
    "        df['vwap_cumsum'] = df['notional'].cumsum().astype(int).div(df['target_prt'].cumsum().astype(int))\n",
    "        df['fees'] = (df['notional'] * fee_rate / 1e4).astype(int)\n",
    "        df['market_vwap'] = (\n",
    "            (df['SizeBillionths'] * (df['PriceMillionths'] / 1e6)).cumsum() /\n",
    "            (df['SizeBillionths']).cumsum())\n",
    "\n",
    "        df['since_arrival'] = df['dt_ds'] - df['dt_ds'].iloc[0]\n",
    "\n",
    "        # DEBUG\n",
    "        # df['market_vwap_side'] = (\n",
    "        #     (df.loc[same_side, 'SizeBillionths'] * (df.loc[same_side, 'PriceMillionths'] / 1e6)).cumsum() /\n",
    "        #     (df.loc[same_side, 'SizeBillionths']).cumsum())\n",
    "        # assert not (df['market_vwap'] - df['vwap_cumsum'] > 2.).any()\n",
    "        vwap = (\n",
    "            (df['SizeBillionths'] * (df['PriceMillionths'] / 1e6)).sum() /\n",
    "            (df['SizeBillionths']).sum())\n",
    "\n",
    "        traded_notional = df['notional'].sum() / 1e9\n",
    "        if traded_notional < target_notional:\n",
    "            # Raise error if we haven't reached target_notional\n",
    "            raise InsufficientRowsError(\n",
    "                f\"{traded_notional=} {target_notional=}\"\n",
    "            )\n",
    "        else:\n",
    "            # Trim dataframe once we've reached target_notional\n",
    "            last_trade = df[df['notional'].cumsum() / 1e9 > target_notional].iloc[0]\n",
    "            last_idx = int(last_trade.name)\n",
    "            df = df.loc[:last_idx]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/memoize/run_accumulate_strat_468cc0c_20230202.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache fp='data/memoize/run_accumulate_strat_468cc0c_20230202.csv' to write results of function run_accumulate_strat\n",
      "Using cache fp='data/memoize/get_trades_data_885f465_20230202.csv' to write results of function get_trades_data\n",
      "Using cached call from data/memoize/get_trades_data_885f465_20230202.csv\n",
      "CPU times: user 1.14 s, sys: 49 ms, total: 1.19 s\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "runner = AccumulateRunner(side=1, downsample_rate=6)\n",
    "df = runner.run_accumulate_strat(\n",
    "    fp='data/Crypto/2021/For_Homework/trades_narrow_BTC-USD_2021.delim',\n",
    "    start_date='1970-01-01', # trim data before this date\n",
    "    target_prt_rate=0.01, # 1% of traded volume\n",
    "    target_notional=1e6, # stop trading when notional has reached this\n",
    "    fee_rate=50, # basis points on notional\n",
    "    row_limit=1e5, # number of trades to pull from data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PriceMillionths</th>\n",
       "      <th>SizeBillionths</th>\n",
       "      <th>Side</th>\n",
       "      <th>dt_ds</th>\n",
       "      <th>is_qual</th>\n",
       "      <th>cum_volm_side</th>\n",
       "      <th>cum_volm_all</th>\n",
       "      <th>cum_volm_qual</th>\n",
       "      <th>target_prt</th>\n",
       "      <th>target_prt_cumsum</th>\n",
       "      <th>notional</th>\n",
       "      <th>vwap_cumsum</th>\n",
       "      <th>fees</th>\n",
       "      <th>market_vwap</th>\n",
       "      <th>since_arrival</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1618091183064028000</th>\n",
       "      <td>58946360000</td>\n",
       "      <td>29417260</td>\n",
       "      <td>1</td>\n",
       "      <td>1618091183064000000</td>\n",
       "      <td>1</td>\n",
       "      <td>56024695730</td>\n",
       "      <td>56024695730</td>\n",
       "      <td>29094351790</td>\n",
       "      <td>294,172.6000</td>\n",
       "      <td>290,943,517.9000</td>\n",
       "      <td>17,340,403,981.7360</td>\n",
       "      <td>59,106.8037</td>\n",
       "      <td>86702019</td>\n",
       "      <td>59,115.4844</td>\n",
       "      <td>1049593000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618091183064028000</th>\n",
       "      <td>58933440000</td>\n",
       "      <td>20260760</td>\n",
       "      <td>1</td>\n",
       "      <td>1618091183064000000</td>\n",
       "      <td>0</td>\n",
       "      <td>56044956490</td>\n",
       "      <td>56044956490</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>290,943,517.9000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>59,106.8037</td>\n",
       "      <td>0</td>\n",
       "      <td>59,115.4186</td>\n",
       "      <td>1049593000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618091183855674000</th>\n",
       "      <td>58942030000</td>\n",
       "      <td>8310870</td>\n",
       "      <td>1</td>\n",
       "      <td>1618091183856000000</td>\n",
       "      <td>1</td>\n",
       "      <td>56053267360</td>\n",
       "      <td>56053267360</td>\n",
       "      <td>29102662660</td>\n",
       "      <td>83,108.7000</td>\n",
       "      <td>291,026,626.6000</td>\n",
       "      <td>4,898,595,488.6610</td>\n",
       "      <td>59,106.7566</td>\n",
       "      <td>24492977</td>\n",
       "      <td>59,115.3929</td>\n",
       "      <td>1050385000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618091185148458000</th>\n",
       "      <td>58942030000</td>\n",
       "      <td>14959600</td>\n",
       "      <td>1</td>\n",
       "      <td>1618091185149000000</td>\n",
       "      <td>1</td>\n",
       "      <td>56068226960</td>\n",
       "      <td>56068226960</td>\n",
       "      <td>29117622260</td>\n",
       "      <td>149,596.0000</td>\n",
       "      <td>291,176,222.6000</td>\n",
       "      <td>8,817,491,919.8800</td>\n",
       "      <td>59,106.6720</td>\n",
       "      <td>44087459</td>\n",
       "      <td>59,115.3466</td>\n",
       "      <td>1051678000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618091185306019000</th>\n",
       "      <td>58942030000</td>\n",
       "      <td>152160</td>\n",
       "      <td>1</td>\n",
       "      <td>1618091185306000000</td>\n",
       "      <td>1</td>\n",
       "      <td>56068379120</td>\n",
       "      <td>56068379120</td>\n",
       "      <td>29117774420</td>\n",
       "      <td>1,521.6000</td>\n",
       "      <td>291,177,744.2000</td>\n",
       "      <td>89,686,192.8480</td>\n",
       "      <td>59,106.6710</td>\n",
       "      <td>448430</td>\n",
       "      <td>59,115.3462</td>\n",
       "      <td>1051835000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PriceMillionths  SizeBillionths  Side  \\\n",
       "dt                                                           \n",
       "1618091183064028000      58946360000        29417260     1   \n",
       "1618091183064028000      58933440000        20260760     1   \n",
       "1618091183855674000      58942030000         8310870     1   \n",
       "1618091185148458000      58942030000        14959600     1   \n",
       "1618091185306019000      58942030000          152160     1   \n",
       "\n",
       "                                   dt_ds  is_qual  cum_volm_side  \\\n",
       "dt                                                                 \n",
       "1618091183064028000  1618091183064000000        1    56024695730   \n",
       "1618091183064028000  1618091183064000000        0    56044956490   \n",
       "1618091183855674000  1618091183856000000        1    56053267360   \n",
       "1618091185148458000  1618091185149000000        1    56068226960   \n",
       "1618091185306019000  1618091185306000000        1    56068379120   \n",
       "\n",
       "                     cum_volm_all cum_volm_qual   target_prt  \\\n",
       "dt                                                             \n",
       "1618091183064028000   56024695730   29094351790 294,172.6000   \n",
       "1618091183064028000   56044956490          <NA>       0.0000   \n",
       "1618091183855674000   56053267360   29102662660  83,108.7000   \n",
       "1618091185148458000   56068226960   29117622260 149,596.0000   \n",
       "1618091185306019000   56068379120   29117774420   1,521.6000   \n",
       "\n",
       "                    target_prt_cumsum            notional  vwap_cumsum  \\\n",
       "dt                                                                       \n",
       "1618091183064028000  290,943,517.9000 17,340,403,981.7360  59,106.8037   \n",
       "1618091183064028000  290,943,517.9000              0.0000  59,106.8037   \n",
       "1618091183855674000  291,026,626.6000  4,898,595,488.6610  59,106.7566   \n",
       "1618091185148458000  291,176,222.6000  8,817,491,919.8800  59,106.6720   \n",
       "1618091185306019000  291,177,744.2000     89,686,192.8480  59,106.6710   \n",
       "\n",
       "                         fees market_vwap  since_arrival  \n",
       "dt                                                        \n",
       "1618091183064028000  86702019 59,115.4844  1049593000000  \n",
       "1618091183064028000         0 59,115.4186  1049593000000  \n",
       "1618091183855674000  24492977 59,115.3929  1050385000000  \n",
       "1618091185148458000  44087459 59,115.3466  1051678000000  \n",
       "1618091185306019000    448430 59,115.3462  1051835000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = df.head(2000).tail()\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8093.400000000001"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "809340 * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478238196.66"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8093.40 * 59089900000 / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt\n",
       "1618091183064028000   58,946.3600\n",
       "1618091183064028000   58,946.3600\n",
       "1618091183855674000   58,945.4062\n",
       "1618091185148458000   58,944.4476\n",
       "1618091185306019000   58,944.4406\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo['notional'].cumsum().div(foo['target_prt'].cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59838.52341688931"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vwap = (\n",
    "    (df['SizeBillionths'] * (df['PriceMillionths'] / 1e6)).sum() /\n",
    "    (df['SizeBillionths']).sum())\n",
    "vwap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I've excluded trades that are not on the same `side` as us. In this case, we specified `side = 1`, meaning that we intend to participate in buyer-initiated trades only. The DataFrame is also truncated between our arrival time (`start_date`) and the date of our last trade, i.e. when our `target_notional` has been traded.\n",
    "\n",
    "Descriptions of the columns are as follows:\n",
    "\n",
    "- The index `dt` is simply the `timestamp_utc_nanoseconds` field.\n",
    "- The downsampled timestamp `dt_ds` is the ns timestamp downsampled to the power of 10 specified in `downsample_rate`. In the above case, `downsample_rate = 6`, so we downsample the timestamp to the next microsecond. This is meant to simulate latency in our networking systems.\n",
    "- `is_qual` is a boolean flag that is 1 for a qualified trade.\n",
    "- The `cum_volm_*` variables are the cumulative sum of trade volume on:\n",
    "    - Same side as us\n",
    "    - All trades, including opposite side\n",
    "    - Qualified trades on the same side only\n",
    "- `target_prt` is our targeted participation volume for this trade, i.e. some small percentage of the volume traded at this level.\n",
    "- `target_prt_cumsum` is the cumulative sum of `target_prt` over time.\n",
    "- `vwap_cumsum` is _our_ achieved VWAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000096.6643073194"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['notional'].sum() / 1e9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
