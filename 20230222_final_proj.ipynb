{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, probplot\n",
    "import quandl\n",
    "import functools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from memoize.dataframe import memoize_df\n",
    "from lmfit.models import SkewedGaussianModel\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "DARK_MODE = False\n",
    "if DARK_MODE:\n",
    "    plt.style.use('dark_background')\n",
    "    plotly_template = 'plotly_dark'\n",
    "else:\n",
    "    plt.style.use('ggplot')\n",
    "    plotly_template = 'ggplot2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 20230222_final_proj\n",
    "\n",
    "@mpcs\n",
    "@finm33550\n",
    "\n",
    "Ethan Ho 2/22/2023\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration & Helper Functions\n",
    "\n",
    "The following cell contains helper functions and configuration options that I will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secrets(fp='./secrets.json'):\n",
    "    \"\"\"\n",
    "    Reads secret values such as API keys from a JSON-formatted file at `fp`.\n",
    "    \"\"\"\n",
    "    with open(fp, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def get_quandl_api_key() -> str:\n",
    "    \"\"\"\n",
    "    Returns Quandl API key stored in secrets.json.\n",
    "    \"\"\"\n",
    "    secrets = get_secrets()\n",
    "    key = secrets.get('NASTAQ_DATA_API_KEY')\n",
    "    assert key, f\"NASTAQ_DATA_API_KEY field in secrets.json is empty or does not exist\"\n",
    "    return key\n",
    "\n",
    "def strip_str_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a DataFrame, strips values in columns with string or object\n",
    "    dtype. I noticed that this was an issue when I saw some m_ticker values\n",
    "    like \"AAPL       \" with trailing whitespace.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_object_dtype(df[col]):\n",
    "            df[col] = df[col].str.strip()\n",
    "    return df\n",
    "\n",
    "@memoize_df(cache_dir='data/memoize', cache_lifetime_days=None)\n",
    "def fetch_quandl_table(\n",
    "    name, start_date, end_date, **kw\n",
    ") -> pd.DataFrame:\n",
    "    df = quandl.get_table(\n",
    "        name,\n",
    "        date={'gte': start_date, 'lte': end_date},\n",
    "        api_key=get_quandl_api_key(),\n",
    "        paginate=True,\n",
    "        **kw\n",
    "    )\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "@memoize_df(cache_dir='data/memoize', cache_lifetime_days=None)\n",
    "def fetch_quandl_quotemedia_prices(\n",
    "    start_date, end_date, ticker\n",
    ") -> pd.DataFrame:\n",
    "    return fetch_quandl_table(\n",
    "        name= 'QUOTEMEDIA/PRICES',\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        ticker=ticker,\n",
    "    )\n",
    "\n",
    "@memoize_df(cache_dir='data/memoize', cache_lifetime_days=None)\n",
    "def fetch_quandl_yc(\n",
    "    name, start_date, end_date,\n",
    ") -> pd.DataFrame:\n",
    "    df = quandl.get(\n",
    "        name,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        api_key=get_quandl_api_key(),\n",
    "    ).reset_index().rename(columns={'Date': 'date'})\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "    return df\n",
    "\n",
    "@memoize_df(cache_dir='data/memoize', cache_lifetime_days=None)\n",
    "def fetch_quandl_spot(\n",
    "    symbol, **kw\n",
    ") -> pd.DataFrame:\n",
    "    df = quandl.get(\n",
    "        f'CUR/{symbol}',\n",
    "        **kw\n",
    "    ).reset_index().rename(columns={\n",
    "        'DATE': 'date',\n",
    "        'RATE': f'USD/{symbol}',\n",
    "    })\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "    return df\n",
    "\n",
    "def unique_index_keys(df, level=0) -> List[str]:\n",
    "    return df.index.get_level_values(level=level).unique().tolist()\n",
    "\n",
    "def get_next_day_of_week(date, day_of_week: int) -> str:\n",
    "    \"\"\"\n",
    "    Monday = 0, Wednesday = 2\n",
    "    \"\"\"\n",
    "    as_dt = pd.to_datetime(date)\n",
    "    days_until = (day_of_week - as_dt.day_of_week) % 7\n",
    "    out_dt = as_dt + pd.to_timedelta(days_until, 'D')\n",
    "    return out_dt.strftime('%Y-%m-%d')\n",
    "\n",
    "def get_standard_yc_cols(cols: List, col_prefix='') -> Dict:\n",
    "    out = dict()\n",
    "    for col_raw in cols:\n",
    "        col = col_raw.lower()\n",
    "        col = re.sub(r'-year', 'y', col)\n",
    "        col = re.sub(r'-month', 'm', col)\n",
    "        if col_prefix:\n",
    "            col = col_prefix + '_' + col\n",
    "        out[col_raw] = col\n",
    "    return out\n",
    "\n",
    "def get_yc(*args, col_prefix='', **kw):\n",
    "    df = fetch_quandl_yc(*args, **kw)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df.rename(columns=get_standard_yc_cols(df.columns, col_prefix), inplace=True)\n",
    "    return df\n",
    "\n",
    "@functools.lru_cache()\n",
    "def get_col_groups(cols) -> Dict:\n",
    "    \"\"\"\n",
    "    get_col_groups(tuple(yc_daily.columns.tolist()))\n",
    "    \"\"\"\n",
    "    out = dict()\n",
    "    for col in cols:\n",
    "        prefix, tenor_raw = col.split('_')\n",
    "        tenor, unit = tenor_raw[:-1], tenor_raw[-1]\n",
    "        if prefix not in out:\n",
    "            out[prefix] = list()\n",
    "        item = {\n",
    "            'col': col,\n",
    "            'country': prefix,\n",
    "            'tenor': tenor,\n",
    "            'unit': unit\n",
    "        }\n",
    "        out[prefix].append(item)\n",
    "    return out\n",
    "\n",
    "def bond_price(zcb, coupon_rate, tenor, coupon_freq):\n",
    "    \"\"\"\n",
    "    Adapted from Zero_And_Spot_Curves.ipynb\n",
    "    \"\"\"\n",
    "    times = np.arange(tenor, 0, step=-coupon_freq)[::-1]\n",
    "    if times.shape[0] == 0:\n",
    "        p = 1.0\n",
    "    else:\n",
    "        r = np.interp(times, zcb.index.values, zcb.values) # Linear interpolation\n",
    "        p = np.exp(-tenor*r[-1]) + coupon_freq * coupon_rate * np.exp(-r*times).sum()\n",
    "    return p\n",
    "\n",
    "def get_zcb_curve(spot, coupons_per_year=4):\n",
    "    \"\"\"\n",
    "    Adapted from Zero_And_Spot_Curves.ipynb\n",
    "    \"\"\"\n",
    "    cpn_freq = 1 / float(coupons_per_year)\n",
    "    for tenor, spot_rate in spot.items():\n",
    "        if tenor > 0.001:\n",
    "            times = np.arange(tenor-cpn_freq, 0, step=-cpn_freq)[::-1]\n",
    "            coupon_half_yr = cpn_freq * spot_rate\n",
    "            z = np.interp(times, spot.index.values, spot.values) # Linear interpolation\n",
    "            preceding_coupons_val = (coupon_half_yr*np.exp(-z*times)).sum()\n",
    "            # Question: tenor here needs to be 5 because all coupons at 5Y swap rate?\n",
    "            # Answer: since we're only using 5Y rates, don't need to change this\n",
    "            spot.loc[tenor] = -np.log((1-preceding_coupons_val)/(1+coupon_half_yr))/tenor\n",
    "    \n",
    "    # Calculate bond price for maturities T = 5 years and S = 5 years - 1 week\n",
    "    T = 5.\n",
    "    S = 4. + (51./52.)\n",
    "    spot_copy = spot.copy()\n",
    "    spot.loc['rt'] = bond_price(spot_copy, coupon_rate=spot.loc[5], tenor=T, coupon_freq=cpn_freq)\n",
    "    spot.loc['rs'] = bond_price(spot_copy, coupon_rate=spot.loc[5], tenor=S, coupon_freq=cpn_freq)\n",
    "    return spot\n",
    "\n",
    "def get_zcb_curves(row):\n",
    "    # Get groups by column prefix\n",
    "    grps: Dict[List[Dict]] = get_col_groups(tuple(row.columns.tolist()))\n",
    "    zcb_dict = dict()\n",
    "    for cty, cols in grps.items():\n",
    "        df = pd.DataFrame.from_records(cols).convert_dtypes()\n",
    "        df['tenor'] = df['tenor'].astype(int)\n",
    "        df.set_index(['tenor', 'unit'], inplace=True)\n",
    "        try:\n",
    "            lo_col = df.loc[(1, 'y'), 'col']\n",
    "            lo = row[lo_col]\n",
    "            lo.name = 1\n",
    "        except KeyError:\n",
    "            lo_col = df.loc[(12, 'm'), 'col']\n",
    "            lo = row[lo_col]\n",
    "            lo.name = 1\n",
    "        try:\n",
    "            mid_col = df.loc[(2, 'y'), 'col']\n",
    "            mid = row[mid_col]\n",
    "            mid.name = 2\n",
    "        except KeyError:\n",
    "            mid_col = df.loc[(3, 'y'), 'col']\n",
    "            mid = row[mid_col]\n",
    "            mid.name = 3\n",
    "        hi_col = df.loc[(5, 'y'), 'col']\n",
    "        hi = row[hi_col]\n",
    "        hi.name = 5\n",
    "        \n",
    "        zcb = (pd.concat([lo, mid, hi], axis=1) / 100).apply(get_zcb_curve, axis=1)\n",
    "        zcb.rename(columns={\n",
    "            lo.name: f\"{lo_col}_zcb\",\n",
    "            mid.name: f\"{mid_col}_zcb\",\n",
    "            hi.name: f\"{hi_col}_zcb\",\n",
    "            'rt': f\"{cty}_rt\",\n",
    "            'rs': f\"{cty}_rs\",\n",
    "        }, inplace=True)\n",
    "        zcb_dict[cty] = zcb\n",
    "    return zcb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fetch Data\n",
    "\n",
    "First, let's set our time indices. We choose to trade weekly on Wednesdays, and skip the week if the Wednesday falls on a holiday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '1990-01-01'\n",
    "end_date = '2022-12-16'\n",
    "\n",
    "daily_idx = pd.date_range(start_date, end_date)\n",
    "first_wed = get_next_day_of_week(start_date, 2)\n",
    "wed_idx_w_holidays = pd.date_range(first_wed, end_date, freq='7D')\n",
    "assert all(date.day_of_week == 2 for date in wed_idx_w_holidays)\n",
    "\n",
    "wed_idx = [\n",
    "    date for date in wed_idx_w_holidays\n",
    "    if date not in pd.to_datetime([\n",
    "        # Remove Wednesdays that fall on holidays\n",
    "        '2012-12-26', '2013-12-25', '2014-01-01', '2018-12-26',\n",
    "        '2019-12-25', '2020-01-01',\n",
    "    ])\n",
    "]\n",
    "assert len(wed_idx_w_holidays) > len(wed_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
