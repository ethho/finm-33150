{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I install my own implementation of Professor Boonstra's \"memoize DataFrame to disk\" feature. The source code can be found at [github.com/ethho/memoize](https://github.com/ethho/memoize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --quiet git+https://github.com/ethho/memoize.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, probplot\n",
    "import quandl\n",
    "import functools\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from memoize.dataframe import memoize_df\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "DARK_MODE = False\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 20230217_hw6_ho_ethan_12350006\n",
    "\n",
    "@mpcs\n",
    "@finm33550\n",
    "\n",
    "Ethan Ho 2/17/2023\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration & Helper Functions\n",
    "\n",
    "The following cell contains helper functions and configuration options that I will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secrets(fp='./secrets.json'):\n",
    "    \"\"\"\n",
    "    Reads secret values such as API keys from a JSON-formatted file at `fp`.\n",
    "    \"\"\"\n",
    "    with open(fp, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def get_quandl_api_key() -> str:\n",
    "    \"\"\"\n",
    "    Returns Quandl API key stored in secrets.json.\n",
    "    \"\"\"\n",
    "    secrets = get_secrets()\n",
    "    key = secrets.get('NASTAQ_DATA_API_KEY')\n",
    "    assert key, f\"NASTAQ_DATA_API_KEY field in secrets.json is empty or does not exist\"\n",
    "    return key\n",
    "\n",
    "def strip_str_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a DataFrame, strips values in columns with string or object\n",
    "    dtype. I noticed that this was an issue when I saw some m_ticker values\n",
    "    like \"AAPL       \" with trailing whitespace.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_object_dtype(df[col]):\n",
    "            df[col] = df[col].str.strip()\n",
    "    return df\n",
    "\n",
    "@memoize_df(cache_dir='data/memoize', cache_lifetime_days=None)\n",
    "def fetch_quandl_table(\n",
    "    name, start_date, end_date, **kw\n",
    ") -> pd.DataFrame:\n",
    "    df = quandl.get_table(\n",
    "        name,\n",
    "        date={'gte': start_date, 'lte': end_date},\n",
    "        api_key=get_quandl_api_key(),\n",
    "        paginate=True,\n",
    "        **kw\n",
    "    )\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "@memoize_df(cache_dir='data/memoize', cache_lifetime_days=None)\n",
    "def fetch_quandl_quotemedia_prices(\n",
    "    start_date, end_date, ticker\n",
    ") -> pd.DataFrame:\n",
    "    return fetch_quandl_table(\n",
    "        name= 'QUOTEMEDIA/PRICES',\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        ticker=ticker,\n",
    "    )\n",
    "\n",
    "def unique_index_keys(df, level=0) -> List[str]:\n",
    "    return df.index.get_level_values(level=level).unique().tolist()\n",
    "\n",
    "def get_next_day_of_week(date, day_of_week: int) -> str:\n",
    "    \"\"\"\n",
    "    Monday = 0, Wednesday = 2\n",
    "    \"\"\"\n",
    "    as_dt = pd.to_datetime(date)\n",
    "    days_until = (day_of_week - as_dt.day_of_week) % 7\n",
    "    out_dt = as_dt + pd.to_timedelta(days_until, 'D')\n",
    "    return out_dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fetch Data\n",
    "\n",
    "First, let's set our time indices. We choose to trade weekly on Wednesdays, and skip the week if the Wednesday falls on a holiday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2017-12-23'\n",
    "end_date = '2022-12-30'\n",
    "\n",
    "daily_idx = pd.date_range(start_date, end_date)\n",
    "first_wed = get_next_day_of_week(start_date, 2)\n",
    "wed_idx_w_holidays = pd.date_range(first_wed, end_date, freq='7D')\n",
    "assert all(date.day_of_week == 2 for date in wed_idx_w_holidays)\n",
    "\n",
    "wed_idx = [\n",
    "    date for date in wed_idx_w_holidays\n",
    "    if date not in pd.to_datetime([\n",
    "        # Remove Wednesdays that fall on holidays\n",
    "        '2012-12-26', '2013-12-25', '2014-01-01', '2018-12-26',\n",
    "        '2019-12-25', '2020-01-01',\n",
    "    ])\n",
    "]\n",
    "assert len(wed_idx_w_holidays) > len(wed_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the 5 year CDS rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache fp='./data/memoize/_get_cds_quotes_558128f_20230215.csv' to write results of function _get_cds_quotes\n",
      "Using cached call from ./data/memoize/_get_cds_quotes_558128f_20230215.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>parspread</th>\n",
       "      <th>upfront</th>\n",
       "      <th>runningcoupon</th>\n",
       "      <th>cdsrealrecovery</th>\n",
       "      <th>cdsassumedrecovery</th>\n",
       "      <th>impliedrating</th>\n",
       "      <th>parspread_ret</th>\n",
       "      <th>upfront_ret</th>\n",
       "      <th>runningcoupon_ret</th>\n",
       "      <th>cdsrealrecovery_ret</th>\n",
       "      <th>cdsassumedrecovery_ret</th>\n",
       "      <th>impliedrating_ret</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">BA</th>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0390</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0398</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8847</td>\n",
       "      <td>1.0194</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-16</th>\n",
       "      <td>0.0017</td>\n",
       "      <td>-0.0389</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0939</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-23</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.2248</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0296</td>\n",
       "      <td>5.7817</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-30</th>\n",
       "      <td>0.0017</td>\n",
       "      <td>-0.2239</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">XRX</th>\n",
       "      <th>2022-12-06</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0050</td>\n",
       "      <td>-4.1325</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-13</th>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-20</th>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.1295</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0286</td>\n",
       "      <td>1.0332</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0046</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3838 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   parspread  upfront  runningcoupon  cdsrealrecovery  \\\n",
       "ticker date                                                             \n",
       "BA     2018-01-02     0.0018  -0.0390         0.0100           0.4000   \n",
       "       2018-01-09     0.0016  -0.0398         0.0100           0.4000   \n",
       "       2018-01-16     0.0017  -0.0389         0.0100           0.4000   \n",
       "       2018-01-23     0.0018  -0.2248         0.0500           0.4000   \n",
       "       2018-01-30     0.0017  -0.2239         0.0500           0.4000   \n",
       "...                      ...      ...            ...              ...   \n",
       "XRX    2022-12-06     0.0424   0.1306         0.0100           0.4000   \n",
       "       2022-12-13     0.0410   0.1253         0.0100           0.4000   \n",
       "       2022-12-20     0.0422   0.1295         0.0100           0.4000   \n",
       "       2022-12-27     0.0424   0.1294         0.0100           0.4000   \n",
       "       2023-01-03     0.0423   0.1289         0.0100           0.4000   \n",
       "\n",
       "                   cdsassumedrecovery  impliedrating  parspread_ret  \\\n",
       "ticker date                                                           \n",
       "BA     2018-01-02              0.4000              3           <NA>   \n",
       "       2018-01-09              0.4000              3         0.8847   \n",
       "       2018-01-16              0.4000              3         1.0939   \n",
       "       2018-01-23              0.4000              3         1.0296   \n",
       "       2018-01-30              0.4000              3         0.9890   \n",
       "...                               ...            ...            ...   \n",
       "XRX    2022-12-06              0.4000              1         1.0050   \n",
       "       2022-12-13              0.4000              1         0.9680   \n",
       "       2022-12-20              0.4000              1         1.0286   \n",
       "       2022-12-27              0.4000              1         1.0046   \n",
       "       2023-01-03              0.4000              1         0.9987   \n",
       "\n",
       "                   upfront_ret  runningcoupon_ret  cdsrealrecovery_ret  \\\n",
       "ticker date                                                              \n",
       "BA     2018-01-02         <NA>               <NA>                 <NA>   \n",
       "       2018-01-09       1.0194             1.0000               1.0000   \n",
       "       2018-01-16       0.9775             1.0000               1.0000   \n",
       "       2018-01-23       5.7817             5.0000               1.0000   \n",
       "       2018-01-30       0.9960             1.0000               1.0000   \n",
       "...                        ...                ...                  ...   \n",
       "XRX    2022-12-06      -4.1325             0.2000               1.0000   \n",
       "       2022-12-13       0.9596             1.0000               1.0000   \n",
       "       2022-12-20       1.0332             1.0000               1.0000   \n",
       "       2022-12-27       0.9996             1.0000               1.0000   \n",
       "       2023-01-03       0.9961             1.0000               1.0000   \n",
       "\n",
       "                   cdsassumedrecovery_ret  impliedrating_ret  \n",
       "ticker date                                                   \n",
       "BA     2018-01-02                    <NA>               <NA>  \n",
       "       2018-01-09                  1.0000             1.0000  \n",
       "       2018-01-16                  1.0000             1.0000  \n",
       "       2018-01-23                  1.0000             1.0000  \n",
       "       2018-01-30                  1.0000             1.0000  \n",
       "...                                   ...                ...  \n",
       "XRX    2022-12-06                  1.0000             1.0000  \n",
       "       2022-12-13                  1.0000             1.0000  \n",
       "       2022-12-20                  1.0000             1.0000  \n",
       "       2022-12-27                  1.0000             1.0000  \n",
       "       2023-01-03                  1.0000             1.0000  \n",
       "\n",
       "[3838 rows x 12 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impliedratingmap = {\n",
    "    'AA': 5,\n",
    "    'A': 4,\n",
    "    'BBB': 3,\n",
    "    'BB': 2,\n",
    "    'B': 1,\n",
    "}\n",
    "\n",
    "@memoize_df(cache_dir='./data/memoize', cache_lifetime_days=None)\n",
    "def _get_cds_quotes(fp='./data/Liq5YCDS.delim'):\n",
    "    df = pd.read_csv(fp, delim_whitespace=True)\n",
    "    assert not df.isnull().any().any()\n",
    "    df.drop(columns=['docclause', 'tier', 'currency', 'tenor'], inplace=True)\n",
    "    df['ticker'] = df['ticker'].str.upper().str.strip()\n",
    "    assert not df.duplicated(['date', 'ticker']).any()\n",
    "    df['impliedrating'] = df['impliedrating'].apply(lambda x: impliedratingmap[x]).astype(int)\n",
    "    return df\n",
    "\n",
    "def get_cds_quotes(fp='./data/Liq5YCDS.delim'):\n",
    "    df = _get_cds_quotes(fp)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.convert_dtypes()\n",
    "    df.sort_values(by=['date', 'ticker'], inplace=True)\n",
    "    df['next_wed'] = pd.to_datetime(df['date'].apply(get_next_day_of_week, args=(1, )))\n",
    "    df = df.groupby(['ticker', 'next_wed'], group_keys=True).aggregate('last')\n",
    "    df.drop(columns=['date'], inplace=True)\n",
    "    df.index.set_names(['ticker', 'date'], inplace=True)\n",
    "    assert not df.isnull().any().any()\n",
    "    return df\n",
    "\n",
    "def get_cds_return():\n",
    "    df = get_cds_quotes()\n",
    "    sh = df.groupby(level=0).shift(1)\n",
    "    change = 1 + ((df - sh) / sh)\n",
    "    change.rename(columns={col: f\"{col}_ret\" for col in change.columns}, inplace=True)\n",
    "    df = df.merge(change, how='left', left_index=True, right_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "cds = get_cds_return()\n",
    "cds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fetch adjusted close prices for the corresponding equities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_52347df_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_52347df_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_913c85c_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_913c85c_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_040b924_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_040b924_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_8477762_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_8477762_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_122b182_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_122b182_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_80bf5df_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_80bf5df_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_b81fe2f_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_b81fe2f_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_3ed4a1f_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_3ed4a1f_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_47be967_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_47be967_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_3927798_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_3927798_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_402e8e0_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_402e8e0_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_70b5dac_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_70b5dac_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_3b9dfa6_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_3b9dfa6_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_6ced558_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_6ced558_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_2671ba3_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_2671ba3_20230215.csv\n",
      "Using cache fp='data/memoize/fetch_quandl_quotemedia_prices_a4f11d4_20230215.csv' to write results of function fetch_quandl_quotemedia_prices\n",
      "Using cached call from data/memoize/fetch_quandl_quotemedia_prices_a4f11d4_20230215.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>eod</th>\n",
       "      <th>eod_ret</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">BA</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>281.4210</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>282.8312</td>\n",
       "      <td>1.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>303.4022</td>\n",
       "      <td>1.0727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-16</th>\n",
       "      <td>319.3427</td>\n",
       "      <td>1.0525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-23</th>\n",
       "      <td>319.7524</td>\n",
       "      <td>1.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">XRX</th>\n",
       "      <th>2022-12-06</th>\n",
       "      <td>15.3300</td>\n",
       "      <td>0.9796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-13</th>\n",
       "      <td>16.5300</td>\n",
       "      <td>1.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-20</th>\n",
       "      <td>14.7100</td>\n",
       "      <td>0.8899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>14.7000</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>14.6000</td>\n",
       "      <td>0.9932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4208 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eod  eod_ret\n",
       "ticker date                        \n",
       "BA     2017-12-26 281.4210     <NA>\n",
       "       2018-01-02 282.8312   1.0050\n",
       "       2018-01-09 303.4022   1.0727\n",
       "       2018-01-16 319.3427   1.0525\n",
       "       2018-01-23 319.7524   1.0013\n",
       "...                    ...      ...\n",
       "XRX    2022-12-06  15.3300   0.9796\n",
       "       2022-12-13  16.5300   1.0783\n",
       "       2022-12-20  14.7100   0.8899\n",
       "       2022-12-27  14.7000   0.9993\n",
       "       2023-01-03  14.6000   0.9932\n",
       "\n",
       "[4208 rows x 2 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = cds.index.get_level_values(0).unique().tolist() + ['SPY']\n",
    "\n",
    "def get_eod_quotes():\n",
    "    eod_dict = dict()\n",
    "    for ticker in tickers:\n",
    "        eod = fetch_quandl_quotemedia_prices(\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            ticker=ticker,\n",
    "        )\n",
    "        eod = eod[[\n",
    "            'date',\n",
    "            'adj_close',\n",
    "        ]]\n",
    "        eod['date'] = pd.to_datetime(eod['date'])\n",
    "        eod.rename(columns=dict(adj_close=ticker), inplace=True)\n",
    "        eod = eod.set_index('date')[ticker]\n",
    "        eod.name = ticker\n",
    "        eod.sort_index(inplace=True)\n",
    "        eod_dict[ticker] = eod\n",
    "    df = pd.DataFrame(eod_dict)\n",
    "    df = df.reset_index().convert_dtypes()\n",
    "    df.sort_values(by=['date'], inplace=True)\n",
    "    df['next_wed'] = pd.to_datetime(df['date'].apply(get_next_day_of_week, args=(1, )))\n",
    "    df = df.groupby('next_wed', group_keys=True).aggregate('last')\n",
    "    df.drop(columns=['date'], inplace=True)\n",
    "    df = df.stack().swaplevel().to_frame(name='eod')\n",
    "    df.index.set_names(['ticker', 'date'], inplace=True)\n",
    "    df.sort_index(level=[0, 1], inplace=True)\n",
    "    assert not df.isnull().any().any()\n",
    "    return df\n",
    "\n",
    "def get_eod_return():\n",
    "    df = get_eod_quotes()\n",
    "    sh = df.groupby(level=0).shift(1)\n",
    "    change = 1 + ((df - sh) / sh)\n",
    "    change.rename(columns={col: f\"{col}_ret\" for col in change.columns}, inplace=True)\n",
    "    df = df.merge(change, how='left', left_index=True, right_index=True)\n",
    "    return df\n",
    "\n",
    "eod = get_eod_return()\n",
    "eod#.loc[(slice(None), '2019-01-08'), :].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>eod</th>\n",
       "      <th>eod_ret</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">BA</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>281.4210</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>282.8312</td>\n",
       "      <td>1.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>303.4022</td>\n",
       "      <td>1.0727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">C</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>63.4956</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>63.1389</td>\n",
       "      <td>0.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>63.9456</td>\n",
       "      <td>1.0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DD</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>92.8490</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>93.4468</td>\n",
       "      <td>1.0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>97.9177</td>\n",
       "      <td>1.0478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>9.8221</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eod  eod_ret\n",
       "ticker date                        \n",
       "BA     2017-12-26 281.4210     <NA>\n",
       "       2018-01-02 282.8312   1.0050\n",
       "       2018-01-09 303.4022   1.0727\n",
       "C      2017-12-26  63.4956     <NA>\n",
       "       2018-01-02  63.1389   0.9944\n",
       "       2018-01-09  63.9456   1.0128\n",
       "DD     2017-12-26  92.8490     <NA>\n",
       "       2018-01-02  93.4468   1.0064\n",
       "       2018-01-09  97.9177   1.0478\n",
       "F      2017-12-26   9.8221     <NA>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eod.loc[(slice(None), slice(None, '2018-01-09')), :].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
